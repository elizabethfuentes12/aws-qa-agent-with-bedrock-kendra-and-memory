location: Mandalay Bay, Level 2 | South, Oceanside D
summary: tag_name :Generative AI, Area of Interest, EC2 Image Builder, Services, Data Protection, Area of Interest, Serverless Compute, Topic, 200 - Intermediate, Level, Wednesday, Day, Mandalay Bay, Venue, DevOps Engineer, Role, Developer/Engineer, Role, AI/ML, Topic, Amazon Elastic Compute Cloud (EC2), Services, Data Scientist, Role, Cross Industry, Industry, , speakers :firstName_0: Miles, lastName_0: Adkins, company_0: Snowflake, , thirdpartyid :AIM208-S, sessionuid :C9EFA374-E7A1-4270-8E79-D5014A51E152, title :LLM inference and fine-tuning on secure enterprise data (sponsored by Snowflake), description :<p>Generative AI and large language models (LLMs) are disrupting the way we work at a global scale. Snowflake is excited to announce an innovative product lineup that brings their platform’s ease-of-use, security, and governance to the world of generative AI. Through these new Snowflake offerings, any user can incorporate LLMs into analytical processes in seconds, and developers can create generative AI–powered applications in minutes or run powerful workflows within hours, like fine-tuning foundation models on governed enterprise data. Join this session to learn more and see demos of the latest functionality, including Streamlit and Snowpark Container Services. This presentation is brought to you by Snowflake, an AWS Partner.</p>, sessiontype :Breakout Session, venuename :Mandalay Bay, floorplanname :Level 2 | South, locationname :Oceanside D, startdatetimeutc :November, 29 2023 22:30:00 -0500, enddatetimeutc :November, 29 2023 23:30:00 -0500, 
enddatetimeutc: November, 29 2023 23:30:00 -0500
startdatetimeutc: November, 29 2023 22:30:00 -0500
locationname: Oceanside D
floorplanname: Level 2 | South
venuename: Mandalay Bay
sessiontype: Breakout Session
description: <p>Generative AI and large language models (LLMs) are disrupting the way we work at a global scale. Snowflake is excited to announce an innovative product lineup that brings their platform’s ease-of-use, security, and governance to the world of generative AI. Through these new Snowflake offerings, any user can incorporate LLMs into analytical processes in seconds, and developers can create generative AI–powered applications in minutes or run powerful workflows within hours, like fine-tuning foundation models on governed enterprise data. Join this session to learn more and see demos of the latest functionality, including Streamlit and Snowpark Container Services. This presentation is brought to you by Snowflake, an AWS Partner.</p>
title: LLM inference and fine-tuning on secure enterprise data (sponsored by Snowflake)
sessionuid: C9EFA374-E7A1-4270-8E79-D5014A51E152
thirdpartyid: AIM208-S
speakers: firstName_0: Miles, lastName_0: Adkins, company_0: Snowflake
tag_name: Generative AI, Area of Interest, EC2 Image Builder, Services, Data Protection, Area of Interest, Serverless Compute, Topic, 200 - Intermediate, Level, Wednesday, Day, Mandalay Bay, Venue, DevOps Engineer, Role, Developer/Engineer, Role, AI/ML, Topic, Amazon Elastic Compute Cloud (EC2), Services, Data Scientist, Role, Cross Industry, Industry
