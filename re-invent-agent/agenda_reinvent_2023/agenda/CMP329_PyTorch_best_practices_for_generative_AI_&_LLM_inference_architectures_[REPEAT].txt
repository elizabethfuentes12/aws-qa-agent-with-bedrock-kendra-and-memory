location: Caesars Forum, Level 1, Alliance 311
summary: tag_name :Monday, Day, Caesars Forum, Venue, AI/ML, Topic, Compute, Topic, Cost Optimization, Area of Interest, Generative AI, Area of Interest, Well-Architected Framework, Area of Interest, Cross Industry, Industry, 300 - Advanced, Level, Data Scientist, Role, Developer/Engineer, Role, Solution/Systems Architect, Role, Amazon Elastic Compute Cloud (EC2), Services, Amazon Elastic Kubernetes Service (EKS), Services, , speakers :firstName_0: Alex, lastName_0: Iankoulski, firstName_1: Keita, lastName_1: Watanabe, firstName_2: Angel, lastName_2: Caballero, firstName_3: Daniel, lastName_3: Zilberman, firstName_4: Judith, lastName_4: Joseph, , thirdpartyid :CMP329-R, sessionuid :31764FE4-915C-45F2-89F6-C4FBFBC7219C, title :PyTorch best practices for generative AI & LLM inference architectures [REPEAT], description :<p>Generative AI and large language models (LLMs) are rapidly disrupting workflows. Inference architectures for these large-scale models need to be carefully constructed to achieve optimal cost performance. In this builders’ session, learn best practices for using PyTorch to deploy LLMs on a cluster of Amazon EC2 Inf2 instances managed by Amazon EKS. Learn how to create a cluster, easily deploy models via AWS Neuron SDK using performant model servers, scale the cluster, benchmark throughput and latency, and observe and monitor utilization of accelerators in your cluster. You must bring your laptop to participate.</p>, sessiontype :standard, venuename :Caesars Forum, floorplanname :Level 1, locationname :Alliance 311, startdatetimeutc :November, 27 2023 21:30:00 -0500, enddatetimeutc :November, 27 2023 22:30:00 -0500, 
enddatetimeutc: November, 27 2023 22:30:00 -0500
startdatetimeutc: November, 27 2023 21:30:00 -0500
locationname: Alliance 311
floorplanname: Level 1
venuename: Caesars Forum
sessiontype: standard
description: <p>Generative AI and large language models (LLMs) are rapidly disrupting workflows. Inference architectures for these large-scale models need to be carefully constructed to achieve optimal cost performance. In this builders’ session, learn best practices for using PyTorch to deploy LLMs on a cluster of Amazon EC2 Inf2 instances managed by Amazon EKS. Learn how to create a cluster, easily deploy models via AWS Neuron SDK using performant model servers, scale the cluster, benchmark throughput and latency, and observe and monitor utilization of accelerators in your cluster. You must bring your laptop to participate.</p>
title: PyTorch best practices for generative AI & LLM inference architectures [REPEAT]
sessionuid: 31764FE4-915C-45F2-89F6-C4FBFBC7219C
thirdpartyid: CMP329-R
speakers: firstName_0: Alex, lastName_0: Iankoulski, firstName_1: Keita, lastName_1: Watanabe, firstName_2: Angel, lastName_2: Caballero, firstName_3: Daniel, lastName_3: Zilberman, firstName_4: Judith, lastName_4: Joseph
tag_name: Monday, Day, Caesars Forum, Venue, AI/ML, Topic, Compute, Topic, Cost Optimization, Area of Interest, Generative AI, Area of Interest, Well-Architected Framework, Area of Interest, Cross Industry, Industry, 300 - Advanced, Level, Data Scientist, Role, Developer/Engineer, Role, Solution/Systems Architect, Role, Amazon Elastic Compute Cloud (EC2), Services, Amazon Elastic Kubernetes Service (EKS), Services
