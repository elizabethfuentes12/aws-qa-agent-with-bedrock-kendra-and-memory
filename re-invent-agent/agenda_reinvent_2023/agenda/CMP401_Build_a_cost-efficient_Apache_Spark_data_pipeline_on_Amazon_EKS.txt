location: Mandalay Bay, Level 2 | South, Mandalay Bay Ballroom D
summary: tag_name :Cross Industry, Industry, Developer/Engineer, Role, Amazon Elastic Compute Cloud (EC2), Services, Data Scientist, Role, Databases, Topic, Monday, Day, Mandalay Bay, Venue, 400 - Expert, Level, Data Engineer, Role, Compute, Topic, Application Integration, Area of Interest, Innovation on AWS, Area of Interest, Well-Architected Framework, Area of Interest, , speakers :firstName_0: Dan, lastName_0: Kelly, firstName_1: Jagdeep, lastName_1: Phoolkumar, , thirdpartyid :CMP401, sessionuid :C063EAAF-3B87-4AD4-B251-AE3321A826AC, title :Build a cost-efficient Apache Spark data pipeline on Amazon EKS, description :<p>Data-driven customers often use multiple platforms to run a variety of data and machine learning workloads. Discover how you can build a unified data platform on Kubernetes to reduce the management overhead of multiple platforms. In this workshop, fill the role of a data architect/engineer and learn to build a data processing pipeline on Kubernetes with a focus on cost efficiency, scalability, and observability. Start with a ready-to-use Amazon EKS cluster and an AWS Cloud9 IDE with Terraform installed. Then, learn to use data on Amazon EKS Blueprints to deploy Apache Airflow, the Kubernetes Operator for Apache Spark, and observability add-ons. You must bring your laptop to participate.</p>, sessiontype :Workshop, venuename :Mandalay Bay, floorplanname :Level 2 | South, locationname :Mandalay Bay Ballroom D, startdatetimeutc :November, 27 2023 16:30:00 -0500, enddatetimeutc :November, 27 2023 18:30:00 -0500, 
enddatetimeutc: November, 27 2023 18:30:00 -0500
startdatetimeutc: November, 27 2023 16:30:00 -0500
locationname: Mandalay Bay Ballroom D
floorplanname: Level 2 | South
venuename: Mandalay Bay
sessiontype: Workshop
description: <p>Data-driven customers often use multiple platforms to run a variety of data and machine learning workloads. Discover how you can build a unified data platform on Kubernetes to reduce the management overhead of multiple platforms. In this workshop, fill the role of a data architect/engineer and learn to build a data processing pipeline on Kubernetes with a focus on cost efficiency, scalability, and observability. Start with a ready-to-use Amazon EKS cluster and an AWS Cloud9 IDE with Terraform installed. Then, learn to use data on Amazon EKS Blueprints to deploy Apache Airflow, the Kubernetes Operator for Apache Spark, and observability add-ons. You must bring your laptop to participate.</p>
title: Build a cost-efficient Apache Spark data pipeline on Amazon EKS
sessionuid: C063EAAF-3B87-4AD4-B251-AE3321A826AC
thirdpartyid: CMP401
speakers: firstName_0: Dan, lastName_0: Kelly, firstName_1: Jagdeep, lastName_1: Phoolkumar
tag_name: Cross Industry, Industry, Developer/Engineer, Role, Amazon Elastic Compute Cloud (EC2), Services, Data Scientist, Role, Databases, Topic, Monday, Day, Mandalay Bay, Venue, 400 - Expert, Level, Data Engineer, Role, Compute, Topic, Application Integration, Area of Interest, Innovation on AWS, Area of Interest, Well-Architected Framework, Area of Interest
